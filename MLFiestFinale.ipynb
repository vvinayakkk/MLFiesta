{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.14",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "sourceId": 9766545,
          "sourceType": "datasetVersion",
          "datasetId": 5981476
        },
        {
          "sourceId": 9794819,
          "sourceType": "datasetVersion",
          "datasetId": 6002390
        },
        {
          "sourceId": 9845020,
          "sourceType": "datasetVersion",
          "datasetId": 6040239
        },
        {
          "sourceId": 9849501,
          "sourceType": "datasetVersion",
          "datasetId": 6043507
        }
      ],
      "dockerImageVersionId": 30787,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "name": "MLFiestFinale",
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "C-2k5mlMjxjj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install langchain_google_genai"
      ],
      "metadata": {
        "trusted": true,
        "id": "P3mC6T5yjxjk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install faiss-cpu"
      ],
      "metadata": {
        "trusted": true,
        "id": "Wvywsw9yjxjk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install sentence-transformers"
      ],
      "metadata": {
        "trusted": true,
        "id": "60fKQJtSjxjk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Person 2**"
      ],
      "metadata": {
        "id": "6Pc_wggMjxjk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import ast\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "import os\n",
        "import time\n",
        "from typing import List\n",
        "import textwrap\n",
        "\n",
        "def chunk_text(text: str, chunk_size: int = 500) -> List[str]:\n",
        "    \"\"\"Split text into smaller chunks while preserving word boundaries.\"\"\"\n",
        "    return textwrap.wrap(text, chunk_size, break_long_words=False)\n",
        "\n",
        "def get_translation(text: str, max_retries: int = 3, delay: int = 2) -> str:\n",
        "    \"\"\"Get a translation from Kannada to English with retry logic.\"\"\"\n",
        "    for attempt in range(max_retries):\n",
        "        try:\n",
        "            prompt = f\"You are a Kannada to English translator. Translate the following text to English, maintaining the context and meaning: {text}\"\n",
        "            response = llm.invoke(prompt)\n",
        "            return str(response.content) if response else \"No response generated.\"\n",
        "        except Exception as e:\n",
        "            if \"429\" in str(e) and attempt < max_retries - 1:\n",
        "                wait_time = delay * (attempt + 1)\n",
        "                print(f\"Rate limit hit, waiting {wait_time} seconds...\")\n",
        "                time.sleep(wait_time)\n",
        "                continue\n",
        "            print(f\"Translation error: {str(e)}\")\n",
        "            return f\"Error: {str(e)}\"\n",
        "    return \"Failed after maximum retries\"\n",
        "\n",
        "def translate_large_text(text: str, chunk_size: int = 500) -> str:\n",
        "    \"\"\"Translate a large text by breaking it into chunks.\"\"\"\n",
        "    if not text or text.isspace():\n",
        "        return \"\"\n",
        "\n",
        "    chunks = chunk_text(text, chunk_size)\n",
        "    translated_chunks = []\n",
        "\n",
        "    for i, chunk in enumerate(chunks):\n",
        "        print(f\"Translating chunk {i+1}/{len(chunks)} ({len(chunk)} characters)\")\n",
        "        translated_chunk = get_translation(chunk)\n",
        "        translated_chunks.append(translated_chunk)\n",
        "        time.sleep(1)\n",
        "\n",
        "    return \" \".join(translated_chunks)\n",
        "\n",
        "def translate_time_aligned_transcripts(time_aligned_dict: dict) -> dict:\n",
        "    \"\"\"Translate each chunk in the time-aligned transcripts.\"\"\"\n",
        "    translated_dict = {}\n",
        "\n",
        "    try:\n",
        "        if isinstance(time_aligned_dict, str):\n",
        "            time_aligned_dict = ast.literal_eval(time_aligned_dict)\n",
        "\n",
        "        for time_key, text in time_aligned_dict.items():\n",
        "            print(f\"Translating chunk for {time_key}\")\n",
        "            translated_text = get_translation(text)\n",
        "            translated_dict[time_key] = translated_text\n",
        "            time.sleep(1)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing time-aligned transcripts: {str(e)}\")\n",
        "        return {}\n",
        "\n",
        "    return translated_dict\n"
      ],
      "metadata": {
        "id": "QqTaoiGdjxjl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyC29gObkycJDBjVkEWjhJoJO-HVB0pC00E\"  # Replace with your key\n",
        "\n",
        "# Initialize the model\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-pro\", temperature=0.7)\n",
        "\n",
        "# Read the original CSV\n",
        "df = pd.read_csv('kannada_english_transcriptions.csv')\n",
        "\n",
        "# Add new columns if they don't exist\n",
        "if 'full_transcript_translation' not in df.columns:\n",
        "    df['full_transcript_translation'] = None\n",
        "if 'time_aligned_translations' not in df.columns:\n",
        "    df['time_aligned_translations'] = None\n",
        "\n",
        "# Process files 24-47\n",
        "for idx in range(24, 48):\n",
        "    if idx >= len(df):\n",
        "        break\n",
        "\n",
        "    row = df.iloc[idx]\n",
        "    print(f\"\\nProcessing file {idx - 23}/24: {row['audio_file']}\")\n",
        "\n",
        "    try:\n",
        "        # Skip if it's the English file\n",
        "        if row['audio_file'] == \"SandalWoodNewsStories_53.mp3\":\n",
        "            print(\"Skipping English audio file...\")\n",
        "            df.at[idx, 'full_transcript_translation'] = row['full_transcript']\n",
        "            df.at[idx, 'time_aligned_translations'] = row['time_aligned_transcripts']\n",
        "            continue\n",
        "\n",
        "        # Only translate if not already translated\n",
        "        if pd.isna(df.at[idx, 'full_transcript_translation']):\n",
        "            print(\"Translating full transcript...\")\n",
        "            full_translation = translate_large_text(row['full_transcript'])\n",
        "            df.at[idx, 'full_transcript_translation'] = full_translation\n",
        "\n",
        "        if pd.isna(df.at[idx, 'time_aligned_translations']):\n",
        "            print(\"Translating time-aligned transcripts...\")\n",
        "            time_aligned_translations = translate_time_aligned_transcripts(row['time_aligned_transcripts'])\n",
        "            df.at[idx, 'time_aligned_translations'] = str(time_aligned_translations)\n",
        "\n",
        "        # Save progress after each file\n",
        "        df.iloc[24:48].to_csv('translations_person2.csv', index=False, encoding='utf-8')\n",
        "        print(f\"Completed translation for {row['audio_file']}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing row {idx}: {str(e)}\")\n",
        "        continue\n",
        "\n",
        "print(\"\\nPerson 2's translations completed!\")\n"
      ],
      "metadata": {
        "id": "zui6ADE8jxjl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Person 3***"
      ],
      "metadata": {
        "id": "Az7hD7ONjxjl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import ast\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "import os\n",
        "import time\n",
        "from typing import List\n",
        "import textwrap\n",
        "\n",
        "def chunk_text(text: str, chunk_size: int = 500) -> List[str]:\n",
        "    \"\"\"Split text into smaller chunks while preserving word boundaries.\"\"\"\n",
        "    return textwrap.wrap(text, chunk_size, break_long_words=False)\n",
        "\n",
        "def get_translation(text: str, max_retries: int = 3, delay: int = 2) -> str:\n",
        "    \"\"\"Get a translation from Kannada to English with retry logic.\"\"\"\n",
        "    for attempt in range(max_retries):\n",
        "        try:\n",
        "            prompt = f\"You are a Kannada to English translator. Translate the following text to English, maintaining the context and meaning: {text}\"\n",
        "            response = llm.invoke(prompt)\n",
        "            return str(response.content) if response else \"No response generated.\"\n",
        "        except Exception as e:\n",
        "            if \"429\" in str(e) and attempt < max_retries - 1:\n",
        "                wait_time = delay * (attempt + 1)\n",
        "                print(f\"Rate limit hit, waiting {wait_time} seconds...\")\n",
        "                time.sleep(wait_time)\n",
        "                continue\n",
        "            print(f\"Translation error: {str(e)}\")\n",
        "            return f\"Error: {str(e)}\"\n",
        "    return \"Failed after maximum retries\"\n",
        "\n",
        "def translate_large_text(text: str, chunk_size: int = 500) -> str:\n",
        "    \"\"\"Translate a large text by breaking it into chunks.\"\"\"\n",
        "    if not text or text.isspace():\n",
        "        return \"\"\n",
        "\n",
        "    chunks = chunk_text(text, chunk_size)\n",
        "    translated_chunks = []\n",
        "\n",
        "    for i, chunk in enumerate(chunks):\n",
        "        print(f\"Translating chunk {i+1}/{len(chunks)} ({len(chunk)} characters)\")\n",
        "        translated_chunk = get_translation(chunk)\n",
        "        translated_chunks.append(translated_chunk)\n",
        "        time.sleep(1)\n",
        "\n",
        "    return \" \".join(translated_chunks)\n",
        "\n",
        "def translate_time_aligned_transcripts(time_aligned_dict: dict) -> dict:\n",
        "    \"\"\"Translate each chunk in the time-aligned transcripts.\"\"\"\n",
        "    translated_dict = {}\n",
        "\n",
        "    try:\n",
        "        if isinstance(time_aligned_dict, str):\n",
        "            time_aligned_dict = ast.literal_eval(time_aligned_dict)\n",
        "\n",
        "        for time_key, text in time_aligned_dict.items():\n",
        "            print(f\"Translating chunk for {time_key}\")\n",
        "            translated_text = get_translation(text)\n",
        "            translated_dict[time_key] = translated_text\n",
        "            time.sleep(1)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing time-aligned transcripts: {str(e)}\")\n",
        "        return {}\n",
        "\n",
        "    return translated_dict\n"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2024-11-16T19:00:39.404773Z",
          "iopub.execute_input": "2024-11-16T19:00:39.405196Z",
          "iopub.status.idle": "2024-11-16T19:00:41.840284Z",
          "shell.execute_reply.started": "2024-11-16T19:00:39.405151Z",
          "shell.execute_reply": "2024-11-16T19:00:41.839498Z"
        },
        "trusted": true,
        "id": "ZJCScExsjxjm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyD7eJyGM-Twi4Z-XUVdvJ_rGnPcJcFbgR8\"\n",
        "\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-pro\", temperature=0.7)\n",
        "\n",
        "df = pd.read_csv('/kaggle/input/kannada-transcript/kannada_english_transcriptions.csv')\n",
        "\n",
        "if 'full_transcript_translation' not in df.columns:\n",
        "    df['full_transcript_translation'] = None\n",
        "if 'time_aligned_translations' not in df.columns:\n",
        "    df['time_aligned_translations'] = None\n",
        "\n",
        "# Process files 48-end\n",
        "for idx in range(48, len(df)):\n",
        "    row = df.iloc[idx]\n",
        "    print(f\"\\nProcessing file {idx - 47}/{len(df) - 48}: {row['audio_file']}\")\n",
        "\n",
        "    try:\n",
        "        # Skip if it's the English file\n",
        "        if row['audio_file'] == \"SandalWoodNewsStories_53.mp3\":\n",
        "            print(\"Skipping English audio file...\")\n",
        "            df.at[idx, 'full_transcript_translation'] = row['full_transcript']\n",
        "            df.at[idx, 'time_aligned_translations'] = row['time_aligned_transcripts']\n",
        "            continue\n",
        "\n",
        "        # Only translate if not already translated\n",
        "        if pd.isna(df.at[idx, 'full_transcript_translation']):\n",
        "            print(\"Translating full transcript...\")\n",
        "            full_translation = translate_large_text(row['full_transcript'])\n",
        "            df.at[idx, 'full_transcript_translation'] = full_translation\n",
        "\n",
        "        if pd.isna(df.at[idx, 'time_aligned_translations']):\n",
        "            print(\"Translating time-aligned transcripts...\")\n",
        "            time_aligned_translations = translate_time_aligned_transcripts(row['time_aligned_transcripts'])\n",
        "            df.at[idx, 'time_aligned_translations'] = str(time_aligned_translations)\n",
        "\n",
        "        # Save progress after each file\n",
        "        df.iloc[48:].to_csv('translations_person3.csv', index=False, encoding='utf-8')\n",
        "        print(f\"Completed translation for {row['audio_file']}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing row {idx}: {str(e)}\")\n",
        "        continue\n",
        "\n",
        "print(\"\\nPerson 3's translations completed!\")\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "wRbe6LB4jxjm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Combining all the three csv into one"
      ],
      "metadata": {
        "id": "1skJF0x0jxjm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the two CSV files\n",
        "csv1 = pd.read_csv('/kaggle/input/first2people/translations_person1.csv')\n",
        "csv2 = pd.read_csv('/kaggle/input/first2people/translations_person2.csv')\n",
        "csv3 = pd.read_csv('/kaggle/working/translations_person3.csv')\n",
        "# Combine the two files by appending rows\n",
        "combined_csv = pd.concat([csv1, csv2,csv3], ignore_index=True)\n",
        "\n",
        "# Save the combined data to a new CSV file\n",
        "combined_csv.to_csv('allfilescombined.csv', index=False)\n",
        "\n",
        "print(\"The three files have been combined and saved to 'allfilescombined.csv'\")\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "DJrSl8Bdjxjm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df=pd.read_csv(\"/kaggle/input/final-translated-all/allfilescombined.csv\")\n",
        "df.head()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-11-09T05:35:04.664873Z",
          "iopub.execute_input": "2024-11-09T05:35:04.665179Z",
          "iopub.status.idle": "2024-11-09T05:35:06.57873Z",
          "shell.execute_reply.started": "2024-11-09T05:35:04.665144Z",
          "shell.execute_reply": "2024-11-09T05:35:06.577631Z"
        },
        "trusted": true,
        "id": "SACHK499jxjm",
        "outputId": "c2bc4fcd-4e1b-4081-d0eb-da05357db4bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 1,
          "output_type": "execute_result",
          "data": {
            "text/plain": "                      audio_file  \\\n0  SandalWoodNewsStories_179.mp3   \n1  SandalWoodNewsStories_168.mp3   \n2   SandalWoodNewsStories_43.mp3   \n3  SandalWoodNewsStories_176.mp3   \n4  SandalWoodNewsStories_284.mp3   \n\n                                     full_transcript  \\\n0  ([' ಒಂದು ಕಿಲೋ ಎಂಟು ಸಾವಿರರಿಂದ ಹನ್ನೆರಡು ಸಾವಿರ ರೂ...   \n1  ([' ಗಂಧದ ಗುಡಿಯಲ್ಲಿ ಹುಟ್ಟಿರುವ ಕೃಷಿಕರೇ ನೀವು ಕೃಷಿ...   \n2  ([' ಹಾಯ ಇಂಡಿಯಾ ಸೋ ಹೀರೋಸ್ ಆಕ್ಚುಲಿ ನನ್ನ ಬ್ಯಾಂಗಗಳ...   \n3  ([' ನೋಡಿ ಅರಣ್ಯ ನಮ್ ಸರ್ಕಾರ ಸುಮಾರು ಸ್ಕೆಮ್ ಗಳು ಕೊ...   \n4  ([' ಗೆಳೆಯ ರೇ ಚಂದನವನದಿಂದ ಮತ್ತೀಗ ನಾನು ತಾವರೆ ಸೋಟಕ...   \n\n                            time_aligned_transcripts  \\\n0  {'0.00s - 10.00s': \"([' ಒಂದು ಕಿಲೋ ಎಂಟು ಸಾವಿರರಿ...   \n1  {'0.00s - 10.00s': \"([' ಗಂಧದ ಗುಡಿಯಲ್ಲಿ ಹುಟ್ಟಿರ...   \n2  {'0.00s - 10.00s': \"([' ಹಾಯ ಇಂಡಿಯಾ ಸೋ ಹೀರೋಸ್ ಆ...   \n3  {'0.00s - 10.00s': \"([' ನೋಡಿ ಅರಣ್ಯ ನಮ್ ಸರ್ಕಾರ ...   \n4  {'0.00s - 10.00s': \"([' ಗೆಳೆಯ ರೇ ಚಂದನವನದಿಂದ ಮತ...   \n\n                         full_transcript_translation  \\\n0  ([' One kg is eight thousand to twelve thousan...   \n1  ([' You are farmers born in the sandalwood for...   \n2  ([' Hey India so heroes actually my Bangalurul...   \n3  ([' Look, our government is giving around sche...   \n4  [(' Oh friend I am coming now to the lotus pon...   \n\n                           time_aligned_translations  \n0  {'0.00s - 10.00s': '([‘One kilogram is between...  \n1  {'0.00s - 10.00s': \"( ['You are a farmer who w...  \n2  {'0.00s - 10.00s': \"[' Hi India so heroes actu...  \n3  {'0.00s - 10.00s': \"([' Look, our government i...  \n4  {'0.00s - 10.00s': \"([' Friend I'm coming to t...  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>audio_file</th>\n      <th>full_transcript</th>\n      <th>time_aligned_transcripts</th>\n      <th>full_transcript_translation</th>\n      <th>time_aligned_translations</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>SandalWoodNewsStories_179.mp3</td>\n      <td>([' ಒಂದು ಕಿಲೋ ಎಂಟು ಸಾವಿರರಿಂದ ಹನ್ನೆರಡು ಸಾವಿರ ರೂ...</td>\n      <td>{'0.00s - 10.00s': \"([' ಒಂದು ಕಿಲೋ ಎಂಟು ಸಾವಿರರಿ...</td>\n      <td>([' One kg is eight thousand to twelve thousan...</td>\n      <td>{'0.00s - 10.00s': '([‘One kilogram is between...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>SandalWoodNewsStories_168.mp3</td>\n      <td>([' ಗಂಧದ ಗುಡಿಯಲ್ಲಿ ಹುಟ್ಟಿರುವ ಕೃಷಿಕರೇ ನೀವು ಕೃಷಿ...</td>\n      <td>{'0.00s - 10.00s': \"([' ಗಂಧದ ಗುಡಿಯಲ್ಲಿ ಹುಟ್ಟಿರ...</td>\n      <td>([' You are farmers born in the sandalwood for...</td>\n      <td>{'0.00s - 10.00s': \"( ['You are a farmer who w...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>SandalWoodNewsStories_43.mp3</td>\n      <td>([' ಹಾಯ ಇಂಡಿಯಾ ಸೋ ಹೀರೋಸ್ ಆಕ್ಚುಲಿ ನನ್ನ ಬ್ಯಾಂಗಗಳ...</td>\n      <td>{'0.00s - 10.00s': \"([' ಹಾಯ ಇಂಡಿಯಾ ಸೋ ಹೀರೋಸ್ ಆ...</td>\n      <td>([' Hey India so heroes actually my Bangalurul...</td>\n      <td>{'0.00s - 10.00s': \"[' Hi India so heroes actu...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>SandalWoodNewsStories_176.mp3</td>\n      <td>([' ನೋಡಿ ಅರಣ್ಯ ನಮ್ ಸರ್ಕಾರ ಸುಮಾರು ಸ್ಕೆಮ್ ಗಳು ಕೊ...</td>\n      <td>{'0.00s - 10.00s': \"([' ನೋಡಿ ಅರಣ್ಯ ನಮ್ ಸರ್ಕಾರ ...</td>\n      <td>([' Look, our government is giving around sche...</td>\n      <td>{'0.00s - 10.00s': \"([' Look, our government i...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>SandalWoodNewsStories_284.mp3</td>\n      <td>([' ಗೆಳೆಯ ರೇ ಚಂದನವನದಿಂದ ಮತ್ತೀಗ ನಾನು ತಾವರೆ ಸೋಟಕ...</td>\n      <td>{'0.00s - 10.00s': \"([' ಗೆಳೆಯ ರೇ ಚಂದನವನದಿಂದ ಮತ...</td>\n      <td>[(' Oh friend I am coming now to the lotus pon...</td>\n      <td>{'0.00s - 10.00s': \"([' Friend I'm coming to t...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Retrieval Part via RAG"
      ],
      "metadata": {
        "id": "r7EkOIUWjxjn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.schema import Document\n",
        "import ast\n",
        "import re\n",
        "\n",
        "def load_and_prepare_data(csv_path):\n",
        "    df = pd.read_csv(csv_path)\n",
        "\n",
        "\n",
        "    df['time_aligned_transcripts'] = df['time_aligned_transcripts'].apply(ast.literal_eval)\n",
        "    df['time_aligned_translations'] = df['time_aligned_translations'].apply(ast.literal_eval)\n",
        "\n",
        "    return df\n",
        "\n",
        "def create_documents(df):\n",
        "    documents = []\n",
        "\n",
        "    for idx, row in df.iterrows():\n",
        "\n",
        "        for time_range, translation in row['time_aligned_translations'].items():\n",
        "\n",
        "            metadata = {\n",
        "                'audio_file': row['audio_file'],\n",
        "                'time_range': time_range,\n",
        "                'original_text': row['time_aligned_transcripts'].get(time_range, ''),\n",
        "                'full_translation': row['full_transcript_translation']\n",
        "            }\n",
        "\n",
        "            doc = Document(\n",
        "                page_content=translation,\n",
        "                metadata=metadata\n",
        "            )\n",
        "            documents.append(doc)\n",
        "\n",
        "    return documents\n",
        "\n",
        "# Initialize vector store\n",
        "def initialize_vector_store(documents):\n",
        "    embeddings = HuggingFaceEmbeddings(\n",
        "        model_name=\"sentence-transformers/paraphrase-multilingual-mpnet-base-v2\"\n",
        "    )\n",
        "\n",
        "    # Create FAISS index\n",
        "    vector_store = FAISS.from_documents(documents, embeddings)\n",
        "\n",
        "    return vector_store\n",
        "\n",
        "def answer_question(question, vector_store, k=3):\n",
        "    docs = vector_store.similarity_search(question, k=k)\n",
        "\n",
        "    print(\"\\nRelevant passages found:\")\n",
        "    print(\"-\" * 80)\n",
        "\n",
        "    for i, doc in enumerate(docs, 1):\n",
        "        print(f\"\\nPassage {i}:\")\n",
        "        print(f\"Audio File: {doc.metadata['audio_file']}\")\n",
        "        print(f\"Time Range: {doc.metadata['time_range']}\")\n",
        "        print(f\"English Translation: {doc.page_content}\")\n",
        "        print(f\"Original Kannada: {doc.metadata['original_text']}\")\n",
        "        print(\"-\" * 40)\n",
        "\n",
        "    return docs\n",
        "\n",
        "def setup_qa_system(csv_path):\n",
        "    print(\"Loading data...\")\n",
        "    df = load_and_prepare_data(csv_path)\n",
        "\n",
        "    print(\"Creating documents...\")\n",
        "    documents = create_documents(df)\n",
        "\n",
        "    print(\"Initializing vector store...\")\n",
        "    vector_store = initialize_vector_store(documents)\n",
        "\n",
        "    return vector_store\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    csv_path = \"/kaggle/input/final-translated-all/allfilescombined.csv\"\n",
        "    vector_store = setup_qa_system(csv_path)\n",
        "\n",
        "    test_questions = [\n",
        "        \"What is mentioned about farmers?\",\n",
        "        \"Is there any mention about government schemes?\",\n",
        "        \"What is discussed about heroes?\"\n",
        "    ]\n",
        "\n",
        "    print(\"\\nTesting the system with sample questions:\")\n",
        "    for question in test_questions:\n",
        "        print(f\"\\nQuestion: {question}\")\n",
        "        relevant_docs = answer_question(question, vector_store)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-11-09T05:45:48.08125Z",
          "iopub.execute_input": "2024-11-09T05:45:48.081704Z",
          "iopub.status.idle": "2024-11-09T05:46:04.879814Z",
          "shell.execute_reply.started": "2024-11-09T05:45:48.08166Z",
          "shell.execute_reply": "2024-11-09T05:46:04.878806Z"
        },
        "trusted": true,
        "id": "jr73pVlRjxjn",
        "outputId": "19414e29-e02a-4c84-9f51-ea9902d66cbd"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Loading data...\nCreating documents...\nInitializing vector store...\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "\nTesting the system with sample questions:\n\nQuestion: What is mentioned about farmers?\n\nRelevant passages found:\n--------------------------------------------------------------------------------\n\nPassage 1:\nAudio File: SandalWoodNewsStories_156.mp3\nTime Range: 290.00s - 300.00s\nEnglish Translation: ([Farmers are tilling the soil and doing all the ploughing and sowing in the agricultural land.], [Farmers are tilling the soil and doing all the ploughing and sowing in the agricultural land.])\nOriginal Kannada: ([' ಫಾರ್ಮರ್ಸ್ ಆಗ್ರಿಕಲ್ಚರ ಲಂಡ್ ಅಲ್ಲಿ ಫೂಲ ಉಳುಮೆ ಮಾಡ್ಕೊಂಡು ಪ್ಲೋಇಂಗ್ ಎಲ್ಲ ಮಾಡಿ ನೆಟ್ಬೋದು ಆ'], [' ಫಾರ್ಮರ್ಸ್ ಆಗ್ರಿಕಲ್ಚರ ಲಂಡ್ ಅಲ್ಲಿ ಫೂಲ ಉಳುಮೆ ಮಾಡ್ಕೊಂಡು ಪ್ಲೋಇಂಗ್ ಎಲ್ಲ ಮಾಡಿ ನೆಟ್ಬೋದು ಆ'])\n----------------------------------------\n\nPassage 2:\nAudio File: SandalWoodNewsStories_42.mp3\nTime Range: 900.00s - 910.00s\nEnglish Translation: ([' Farmers' Own '], [' Farmers' Own '])\nOriginal Kannada: ([' ರೈತಾ್ ಯ ಅ ಆದ ಬ'], [' ರೈತಾ್ ಯ ಅ ಆದ ಬ'])\n----------------------------------------\n\nPassage 3:\nAudio File: SandalWoodNewsStories_169.mp3\nTime Range: 510.00s - 520.00s\nEnglish Translation: ([ ' Different experts in this subject, farmers who have grown crops will give us information by them ' ], [ ' Different experts in this subject, farmers who have grown crops will give us information by them ' ])\nOriginal Kannada: ([' ಬೇರೆ ಬೇರೆ ಈ ವಿಷಯ ತಜ್ಞರು ಇವರು ಬೆಳೆದಿರೋಂಥ ಬೆಳೆಗಾರರು ನಮಗೆ ಮಾಹಿತಿ ತಿಳಿಸಿರ್ತಾರೆ ಅವರಿಂದ'], [' ಬೇರೆ ಬೇರೆ ಈ ವಿಷಯ ತಜ್ಞರು ಇವರು ಬೆಳೆದಿರೋಂಥ ಬೆಳೆಗಾರರು ನಮಗೆ ಮಾಹಿತಿ ತಿಳಿಸಿರ್ತಾರೆ ಅವರಿಂದ'])\n----------------------------------------\n\nQuestion: Is there any mention about government schemes?\n\nRelevant passages found:\n--------------------------------------------------------------------------------\n\nPassage 1:\nAudio File: SandalWoodNewsStories_176.mp3\nTime Range: 1040.00s - 1050.00s\nEnglish Translation: ([' Look, our government is providing so many schemes. Farmers are not using the government schemes. There are so many schemes. I have brochures of all the departments of the forest'], [' Look, our government is providing so many schemes. Farmers are not using the government schemes. There are so many schemes. I have brochures of all the departments of the forest'])\nOriginal Kannada: ([' ನೋಡಿ ಅರಣ್ಯ ನಮ್ಮ ಸರ್ಕಾರ ಸುಮಾರು ಸ್ಕೀಮ್ಗಳು ಕೊಡ್ತಾ ಇದೆ ಸರ್ಕಾರದ ಸ್ಕೀಮ್ ಗಳನ್ನ ರೈತರು ಬಳಸ್ಕೊತ ಇಲ್ಲಪ್ಪ ಸುಮಾರು ಸ್ಕೀಮ್ ಗಳಿದ್ದಾವೆ ನನ್ನತ್ತ ಸುಮಾರು ಅರಣ್ಯ ಎಲ್ಲಾ ಡಿಪಾರ್ಟ್ಮೆಂಟ್ ಬ್ರೋ ಚರ್ಸ್ ಇದ್ದಾವೆ'], [' ನೋಡಿ ಅರಣ್ಯ ನಮ್ಮ ಸರ್ಕಾರ ಸುಮಾರು ಸ್ಕೀಮ್ಗಳು ಕೊಡ್ತಾ ಇದೆ ಸರ್ಕಾರದ ಸ್ಕೀಮ್ ಗಳನ್ನ ರೈತರು ಬಳಸ್ಕೊತ ಇಲ್ಲಪ್ಪ ಸುಮಾರು ಸ್ಕೀಮ್ ಗಳಿದ್ದಾವೆ ನನ್ನತ್ತ ಸುಮಾರು ಅರಣ್ಯ ಎಲ್ಲಾ ಡಿಪಾರ್ಟ್ಮೆಂಟ್ ಬ್ರೋ ಚರ್ಸ್ ಇದ್ದಾವೆ'])\n----------------------------------------\n\nPassage 2:\nAudio File: SandalWoodNewsStories_169.mp3\nTime Range: 810.00s - 820.00s\nEnglish Translation: ([Steve says it is very expensive. He says that since it is in the initial stage, it will be expensive. Let's see, government], [Steve says it is very expensive. He says that since it is in the initial stage, it will be expensive. Let's see, government])\nOriginal Kannada: (['ಸ್್ತೀವಿ ಅಂತೇಳಿ ಹೇಳ್ತಾಯಿದ್ದಾರೆ ಅದು ತುಂಬ ದುಬಾರಿ ಅಂಂತೇಳಿ ಇನ್ನೂ ಅದನ್ನು ಪ್ರಾರಂಭಿಕ ಹಂತದಲ್ಲಿದೆ ದುಬಾರಿ ಆಗ್ತದೆ ಅಂತೇಳಿ ಹೇಳಿದ್ದಾರೆ ನೋಡೋಣ ಸರ್ಕಾರ'], ['ಸ್್ತೀವಿ ಅಂತೇಳಿ ಹೇಳ್ತಾಯಿದ್ದಾರೆ ಅದು ತುಂಬ ದುಬಾರಿ ಅಂಂತೇಳಿ ಇನ್ನೂ ಅದನ್ನು ಪ್ರಾರಂಭಿಕ ಹಂತದಲ್ಲಿದೆ ದುಬಾರಿ ಆಗ್ತದೆ ಅಂತೇಳಿ ಹೇಳಿದ್ದಾರೆ ನೋಡೋಣ ಸರ್ಕಾರ'])\n----------------------------------------\n\nPassage 3:\nAudio File: SandalWoodNewsStories_43.mp3\nTime Range: 260.00s - 270.00s\nEnglish Translation: ([So basically I heard that the Karnataka Government is providing a lot of support now. Does every state have different rules or is it the same for all states?])\nOriginal Kannada: ([' ಸೋ ಬಸಿಕಾಲಿ ಇವಾಗ ಕರ್ನಾಟಕ ಗವರ್ನಮೆಂಟ್ನು ತುಂಬಾ ಸುಪ್ಪೋರ್ಟ್ ಮಾಡ್ತಾ ಇದೆ ಅಂತ ಕೇಳಿದ್ವಿ ಇದು ಒಂದೊಂದು್ ಸ್ಟೇಟ್ ಗೆ ಒಂದೊಂದು್ ರುಲ್ಸ್ ಏನಾದ್ೂ ಇರುತ್ತೆ ಸಿರ ಇಲ್ಲ ಎಲ್ಲಾ ಸ್ಟೇಟ್ ಗೂ ಒಂದೇ'], [' ಸೋ ಬಸಿಕಾಲಿ ಇವಾಗ ಕರ್ನಾಟಕ ಗವರ್ನಮೆಂಟ್ನು ತುಂಬಾ ಸುಪ್ಪೋರ್ಟ್ ಮಾಡ್ತಾ ಇದೆ ಅಂತ ಕೇಳಿದ್ವಿ ಇದು ಒಂದೊಂದು್ ಸ್ಟೇಟ್ ಗೆ ಒಂದೊಂದು್ ರುಲ್ಸ್ ಏನಾದ್ೂ ಇರುತ್ತೆ ಸಿರ ಇಲ್ಲ ಎಲ್ಲಾ ಸ್ಟೇಟ್ ಗೂ ಒಂದೇ'])\n----------------------------------------\n\nQuestion: What is discussed about heroes?\n\nRelevant passages found:\n--------------------------------------------------------------------------------\n\nPassage 1:\nAudio File: SandalWoodNewsStories_179.mp3\nTime Range: 1320.00s - 1330.00s\nEnglish Translation: ([‘Ta Chandanawasha anta ivella kastili a stud tino kapas santalinas anta heltiwi red sanders anta heltare’], [‘Ta Chandanawasha anta ivella kastili a stud tino kapas santalinas anta heltiwi red sanders anta heltare’])\nOriginal Kannada: (['ತ ಚಂದನ ವಷ ಅಂತ ಇವೆಲ್ಲ ಕಾಸ್ಟ್ಲಿ ಅ ಸ್ಟುಡ್ ಟೀಿನೋ ಕ್ಪಸ್ ಸ್ಯಾಂಟಲೀನಸ್ ಅಂತ ಹೇಳ್ತೀವಿ ರೆಡ್ ಸ್ಯಾಂಡರ್ಸ್ ಅಂತ ಹೇಳ್ತಾರೆ'], ['ತ ಚಂದನ ವಷ ಅಂತ ಇವೆಲ್ಲ ಕಾಸ್ಟ್ಲಿ ಅ ಸ್ಟುಡ್ ಟೀಿನೋ ಕ್ಪಸ್ ಸ್ಯಾಂಟಲೀನಸ್ ಅಂತ ಹೇಳ್ತೀವಿ ರೆಡ್ ಸ್ಯಾಂಡರ್ಸ್ ಅಂತ ಹೇಳ್ತಾರೆ'])\n----------------------------------------\n\nPassage 2:\nAudio File: SandalWoodNewsStories_284.mp3\nTime Range: 160.00s - 170.00s\nEnglish Translation: ([‘he is directing a movie called koshapanda roopa and he can be one of the hero, second hero, or anti hero in that movie’], [‘he is directing a movie called koshapanda roopa and he can be one of the hero, second hero, or anti hero in that movie’])\nOriginal Kannada: ([' ಅವ ಒಂದು ಸಿನಿಮಾ  ದೀರೆಕ್ಟ್ ಮಾಡ್ತಾ ಇದ್ದಾನೆ ಕೋಷಪಾಂಡ ರೂಪ ಅಂತ ಆ ಸಿನಿಮಾದಲ್ಲಿ ಆ ಓನ್ ಆಫ್ ದಿ ಹೀರೋ ಸೆಕೆಂಡ್ ಹೀರೋ ಅಥವಾ ಆಂಟಿ ಹೀರೋ ಏನ್ ಬೇಕಾದೂ ಕ'], [' ಅವ ಒಂದು ಸಿನಿಮಾ  ದೀರೆಕ್ಟ್ ಮಾಡ್ತಾ ಇದ್ದಾನೆ ಕೋಷಪಾಂಡ ರೂಪ ಅಂತ ಆ ಸಿನಿಮಾದಲ್ಲಿ ಆ ಓನ್ ಆಫ್ ದಿ ಹೀರೋ ಸೆಕೆಂಡ್ ಹೀರೋ ಅಥವಾ ಆಂಟಿ ಹೀರೋ ಏನ್ ಬೇಕಾದೂ ಕ'])\n----------------------------------------\n\nPassage 3:\nAudio File: SandalWoodNewsStories_49.mp3\nTime Range: 170.00s - 180.00s\nEnglish Translation: ( [' Ha alavatta Maada NodiNNa KaavoraT'], [' Ha alavatta Maada NodiNNa KaavoraT'])\nOriginal Kannada: ([' ಹಾ ಅಲವತ್ತ ಮಾಡ ನೋಡಿಣ್ಣ ಕಾವೋರಟ್'], [' ಹಾ ಅಲವತ್ತ ಮಾಡ ನೋಡಿಣ್ಣ ಕಾವೋರಟ್'])\n----------------------------------------\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -U langchain-community"
      ],
      "metadata": {
        "trusted": true,
        "id": "NK5ypuE1jxjn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install langchain"
      ],
      "metadata": {
        "trusted": true,
        "id": "9j9Vpyiqjxjn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.schema import Document\n",
        "from pydub import AudioSegment\n",
        "import ast\n",
        "import re\n",
        "import os\n",
        "from typing import List, Dict, Tuple\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        "\n",
        "class AudioRAGSystem:\n",
        "    def __init__(self, csv_path: str, audio_dir: str, output_dir: str = \"./extracted_segments\"):\n",
        "        \"\"\"\n",
        "        Initialize the RAG system with paths for data and audio files.\n",
        "\n",
        "        Args:\n",
        "            csv_path: Path to the CSV file containing transcriptions and translations\n",
        "            audio_dir: Directory containing the audio files\n",
        "            output_dir: Directory to save extracted audio segments\n",
        "        \"\"\"\n",
        "        self.csv_path = csv_path\n",
        "        self.audio_dir = audio_dir\n",
        "        self.output_dir = output_dir\n",
        "        os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "        # Load data and initialize system\n",
        "        self.df = self.load_and_prepare_data()\n",
        "        self.documents = self.create_documents()\n",
        "        self.vector_store = self.initialize_vector_store()\n",
        "\n",
        "        # Cache for loaded audio files\n",
        "        self.audio_cache = {}\n",
        "\n",
        "    def parse_time(self, time_str: str) -> float:\n",
        "        \"\"\"\n",
        "        Parse time string to float, handling various formats.\n",
        "\n",
        "        Args:\n",
        "            time_str: Time string (e.g., \"0.00s\", \"0.00s \", \" 0.00s\", etc.)\n",
        "\n",
        "        Returns:\n",
        "            float: Time in seconds\n",
        "        \"\"\"\n",
        "        cleaned = time_str.strip().rstrip('s').strip()\n",
        "        return float(cleaned)\n",
        "\n",
        "    def load_and_prepare_data(self) -> pd.DataFrame:\n",
        "        \"\"\"Load and prepare the CSV data.\"\"\"\n",
        "        df = pd.read_csv(self.csv_path)\n",
        "\n",
        "        def safe_eval(x):\n",
        "            try:\n",
        "                return ast.literal_eval(x) if isinstance(x, str) else x\n",
        "            except (ValueError, SyntaxError):\n",
        "                return {}\n",
        "\n",
        "        df['time_aligned_transcripts'] = df['time_aligned_transcripts'].apply(safe_eval)\n",
        "        df['time_aligned_translations'] = df['time_aligned_translations'].apply(safe_eval)\n",
        "        return df\n",
        "\n",
        "    def create_documents(self) -> List[Document]:\n",
        "        \"\"\"Create documents for vector store with merged time segments.\"\"\"\n",
        "        documents = []\n",
        "\n",
        "        for idx, row in self.df.iterrows():\n",
        "            try:\n",
        "\n",
        "                time_ranges = sorted(\n",
        "                    row['time_aligned_translations'].keys(),\n",
        "                    key=lambda x: self.parse_time(x.split('-')[0])\n",
        "                )\n",
        "\n",
        "                for i in range(len(time_ranges)):\n",
        "                    combined_text = \"\"\n",
        "                    combined_original = \"\"\n",
        "                    start_time = self.parse_time(time_ranges[i].split('-')[0])\n",
        "\n",
        "                    j = i\n",
        "                    while j < len(time_ranges):\n",
        "                        end_time = self.parse_time(time_ranges[j].split('-')[1])\n",
        "                        if end_time - start_time > 30:\n",
        "                            break\n",
        "\n",
        "                        current_translation = row['time_aligned_translations'].get(time_ranges[j], \"\")\n",
        "                        current_transcript = row['time_aligned_transcripts'].get(time_ranges[j], \"\")\n",
        "\n",
        "                        if current_translation:\n",
        "                            combined_text += \" \" + current_translation\n",
        "                        if current_transcript:\n",
        "                            combined_original += \" \" + current_transcript\n",
        "                        j += 1\n",
        "\n",
        "                    if not combined_text.strip() or not combined_original.strip():\n",
        "                        continue\n",
        "\n",
        "                    metadata = {\n",
        "                        'audio_file': row['audio_file'],\n",
        "                        'start_time': start_time,\n",
        "                        'end_time': end_time,\n",
        "                        'time_range': f\"{start_time:.2f}s - {end_time:.2f}s\",\n",
        "                        'original_text': combined_original.strip(),\n",
        "                        'full_translation': row.get('full_transcript_translation', '')\n",
        "                    }\n",
        "\n",
        "                    doc = Document(\n",
        "                        page_content=combined_text.strip(),\n",
        "                        metadata=metadata\n",
        "                    )\n",
        "                    documents.append(doc)\n",
        "            except Exception as e:\n",
        "                print(f\"Error processing row {idx}: {str(e)}\")\n",
        "                continue\n",
        "\n",
        "        return documents\n",
        "\n",
        "    def initialize_vector_store(self) -> FAISS:\n",
        "        \"\"\"Initialize the FAISS vector store.\"\"\"\n",
        "        embeddings = HuggingFaceEmbeddings(\n",
        "            model_name=\"sentence-transformers/paraphrase-multilingual-mpnet-base-v2\"\n",
        "        )\n",
        "        return FAISS.from_documents(self.documents, embeddings)\n",
        "\n",
        "    def calculate_relevance_score(self, question: str, doc: Document) -> float:\n",
        "        \"\"\"\n",
        "        Calculate a relevance score for a document relative to the question.\n",
        "        Uses a combination of semantic similarity and keyword matching.\n",
        "        \"\"\"\n",
        "        try:\n",
        "\n",
        "            embeddings = HuggingFaceEmbeddings(\n",
        "                model_name=\"sentence-transformers/paraphrase-multilingual-mpnet-base-v2\"\n",
        "            )\n",
        "            question_emb = embeddings.embed_query(question)\n",
        "            doc_emb = embeddings.embed_query(doc.page_content)\n",
        "\n",
        "            semantic_score = F.cosine_similarity(\n",
        "                torch.tensor(question_emb).unsqueeze(0),\n",
        "                torch.tensor(doc_emb).unsqueeze(0)\n",
        "            ).item()\n",
        "\n",
        "            question_words = set(question.lower().split())\n",
        "            doc_words = set(doc.page_content.lower().split())\n",
        "            keyword_score = len(question_words.intersection(doc_words)) / len(question_words)\n",
        "\n",
        "            final_score = 0.7 * semantic_score + 0.3 * keyword_score\n",
        "\n",
        "            return final_score\n",
        "        except Exception as e:\n",
        "            print(f\"Error calculating relevance score: {str(e)}\")\n",
        "            return 0.0\n",
        "\n",
        "    def extract_audio_segment(self, audio_file: str, start_time: float, end_time: float) -> str:\n",
        "        \"\"\"Extract and save an audio segment.\"\"\"\n",
        "        try:\n",
        "\n",
        "            if audio_file not in self.audio_cache:\n",
        "                audio_path = os.path.join(self.audio_dir, audio_file)\n",
        "                self.audio_cache[audio_file] = AudioSegment.from_mp3(audio_path)\n",
        "\n",
        "            audio = self.audio_cache[audio_file]\n",
        "\n",
        "            start_ms = int(start_time * 1000)\n",
        "            end_ms = int(end_time * 1000)\n",
        "\n",
        "            segment = audio[start_ms:end_ms]\n",
        "\n",
        "            output_filename = f\"segment_{audio_file}_{start_time:.2f}_{end_time:.2f}.mp3\"\n",
        "            output_path = os.path.join(self.output_dir, output_filename)\n",
        "            segment.export(output_path, format='mp3')\n",
        "\n",
        "            return output_path\n",
        "        except Exception as e:\n",
        "            print(f\"Error extracting audio segment: {str(e)}\")\n",
        "            return \"\"\n",
        "\n",
        "    def answer_question(self, question: str, k: int = 5) -> List[Dict]:\n",
        "        \"\"\"\n",
        "        Answer a question by retrieving and ranking relevant passages.\n",
        "        Also extracts corresponding audio segments.\n",
        "        \"\"\"\n",
        "        try:\n",
        "\n",
        "            docs = self.vector_store.similarity_search(question, k=k)\n",
        "\n",
        "            scored_docs = [\n",
        "                (doc, self.calculate_relevance_score(question, doc))\n",
        "                for doc in docs\n",
        "            ]\n",
        "            scored_docs.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "            results = []\n",
        "            for doc, score in scored_docs:\n",
        "\n",
        "                audio_path = self.extract_audio_segment(\n",
        "                    doc.metadata['audio_file'],\n",
        "                    doc.metadata['start_time'],\n",
        "                    doc.metadata['end_time']\n",
        "                )\n",
        "\n",
        "                result = {\n",
        "                    'relevance_score': score,\n",
        "                    'audio_file': doc.metadata['audio_file'],\n",
        "                    'time_range': doc.metadata['time_range'],\n",
        "                    'english_translation': doc.page_content,\n",
        "                    'original_kannada': doc.metadata['original_text'],\n",
        "                    'extracted_audio_path': audio_path\n",
        "                }\n",
        "                results.append(result)\n",
        "\n",
        "            return results\n",
        "        except Exception as e:\n",
        "            print(f\"Error answering question: {str(e)}\")\n",
        "            return []\n",
        "\n",
        "    def print_results(self, results: List[Dict]):\n",
        "        \"\"\"Print results in a formatted way.\"\"\"\n",
        "        if not results:\n",
        "            print(\"\\nNo relevant passages found.\")\n",
        "            return\n",
        "\n",
        "        print(\"\\nRelevant passages found (ranked by relevance):\")\n",
        "        print(\"-\" * 80)\n",
        "\n",
        "        for i, result in enumerate(results, 1):\n",
        "            print(f\"\\nPassage {i} (Relevance Score: {result['relevance_score']:.3f}):\")\n",
        "            print(f\"Audio File: {result['audio_file']}\")\n",
        "            print(f\"Time Range: {result['time_range']}\")\n",
        "            print(f\"English Translation: {result['english_translation']}\")\n",
        "            print(f\"Original Kannada: {result['original_kannada']}\")\n",
        "            print(f\"Extracted Audio: {result['extracted_audio_path']}\")\n",
        "            print(\"-\" * 40)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-11-09T06:01:44.512085Z",
          "iopub.execute_input": "2024-11-09T06:01:44.512581Z",
          "iopub.status.idle": "2024-11-09T06:01:44.549101Z",
          "shell.execute_reply.started": "2024-11-09T06:01:44.512532Z",
          "shell.execute_reply": "2024-11-09T06:01:44.548136Z"
        },
        "trusted": true,
        "id": "ltpLPbBKjxjn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "csv_path = \"/kaggle/input/final-translated-all/allfilescombined.csv\"\n",
        "audio_dir = \"/kaggle/input/audio-kannada/audiocorpus\"\n",
        "output_dir = \"/kaggle/working/extracted_segments2\"\n",
        "\n",
        "rag_system = AudioRAGSystem(csv_path, audio_dir, output_dir)\n",
        "\n",
        "def interactive_qa():\n",
        "    while True:\n",
        "        question = input(\"\\nEnter your question (or 'quit' to exit): \")\n",
        "        if question.lower() == 'quit':\n",
        "            break\n",
        "\n",
        "        print(\"\\nSearching for answer...\")\n",
        "        results = rag_system.answer_question(question)\n",
        "        rag_system.print_results(results)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    sample_question = \"What is mentioned about farmers?\"\n",
        "    results = rag_system.answer_question(sample_question)\n",
        "    rag_system.print_results(results)\n",
        "    print(\"\\nEntering interactive mode...\")\n",
        "    interactive_qa()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-11-09T06:01:54.899435Z",
          "iopub.execute_input": "2024-11-09T06:01:54.900302Z",
          "iopub.status.idle": "2024-11-09T06:03:29.707469Z",
          "shell.execute_reply.started": "2024-11-09T06:01:54.900251Z",
          "shell.execute_reply": "2024-11-09T06:03:29.706466Z"
        },
        "trusted": true,
        "id": "n309xVNhjxjo",
        "outputId": "8892cffa-0401-4564-ea93-d8e85396c338"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "\nRelevant passages found (ranked by relevance):\n--------------------------------------------------------------------------------\n\nPassage 1 (Relevance Score: 0.661):\nAudio File: SandalWoodNewsStories_9.mp3\nTime Range: 650.00s - 690.00s\nEnglish Translation: ([My contact with farmers is continuous, different organizations come and hundreds of farmers come under one roof, they themselves come and gather there], [My contact with farmers is continuous, different organizations come and hundreds of farmers come under one roof, they themselves come and gather there]) ([' Every third Sunday of the month, we have a group discussion where farmers can discuss any confusions they have about agroforestry, what to do and not to do'], [' Every third Sunday of the month, we have a group discussion where farmers can discuss any confusions they have about agroforestry, what to do and not to do']) ([' And so what I do is every third Sunday of the month at 9 am, I have a session on agro forestry models on our farm'], [' And so what I do is every third Sunday of the month at 9 am, I have a session on agro forestry models on our farm'])\nOriginal Kannada: ([' ನಿರಂತರ ಇರ್ತದೆ ನನ್ನ ರೈತರ ಸಂಪರ್ಕ ಬೇರೆ ಬೇರೆ ಸಂಘ ಸಂಸ್ಥೆಗಳು ಬರ್ತಾ ಒಂದು ಅಡಿಯಲ್ಲಿ ನೂರಾರು ರೈತರು ಬರ್ತ ಇರ್ತಾರೆ ತಾವೇ ಬಂದು ಬೆಟ್ಟೆ ಹಾಕ್ತಾಯ ಇರ್ತಾರೆ'], [' ನಿರಂತರ ಇರ್ತದೆ ನನ್ನ ರೈತರ ಸಂಪರ್ಕ ಬೇರೆ ಬೇರೆ ಸಂಘ ಸಂಸ್ಥೆಗಳು ಬರ್ತಾ ಒಂದು ಅಡಿಯಲ್ಲಿ ನೂರಾರು ರೈತರು ಬರ್ತ ಇರ್ತಾರೆ ತಾವೇ ಬಂದು ಬೆಟ್ಟೆ ಹಾಕ್ತಾಯ ಇರ್ತಾರೆ']) ([' ಪ್ರತಿ ತಿಂಗಳು ಮೂರನೇ ಭಾನುವಾರ ನಮ್ಮಲ್ಲೊಂದು ಗ್ರೂಪ್ ಡಿಸ್ಕಶನ್ ಇರ್ತದೆ ಯಾವುದಾದ್ರೂ ರೈತರು ಕೃಷಿ ಅರಣ್ಯದ ಬಗ್ಗೆ ಗೊಂದಲಗಳಿರ್ತವೆ ಅದರ ಡೂಸ್ ಏನು ಡೋನ್ಸ್ ಏನು'], [' ಪ್ರತಿ ತಿಂಗಳು ಮೂರನೇ ಭಾನುವಾರ ನಮ್ಮಲ್ಲೊಂದು ಗ್ರೂಪ್ ಡಿಸ್ಕಶನ್ ಇರ್ತದೆ ಯಾವುದಾದ್ರೂ ರೈತರು ಕೃಷಿ ಅರಣ್ಯದ ಬಗ್ಗೆ ಗೊಂದಲಗಳಿರ್ತವೆ ಅದರ ಡೂಸ್ ಏನು ಡೋನ್ಸ್ ಏನು']) ([' ಅಂತ ಹಿಂಗಾಗಿ ಏನು ಮಾಡ್ತೀನಿ ಪ್ರತಿ ತಿಂಗಳು ಮೂರನೇ ಭಾನುವಾರ ಬೆಳಗ್ಗೆ ಒಂಬತ್ತು ಗಂಟೆಗೆ ನಮ್ಮಲ್ಲೊಂದು ಕೃಷಿ ಅರಣ್ಯ ಪದ್ಧತಿ ಮಾದರಿಗಳ ಬಗ್ಗೆ ಒಂದು ವಿಚಾರ'], [' ಅಂತ ಹಿಂಗಾಗಿ ಏನು ಮಾಡ್ತೀನಿ ಪ್ರತಿ ತಿಂಗಳು ಮೂರನೇ ಭಾನುವಾರ ಬೆಳಗ್ಗೆ ಒಂಬತ್ತು ಗಂಟೆಗೆ ನಮ್ಮಲ್ಲೊಂದು ಕೃಷಿ ಅರಣ್ಯ ಪದ್ಧತಿ ಮಾದರಿಗಳ ಬಗ್ಗೆ ಒಂದು ವಿಚಾರ'])\nExtracted Audio: /kaggle/working/extracted_segments2/segment_SandalWoodNewsStories_9.mp3_650.00_690.00.mp3\n----------------------------------------\n\nPassage 2 (Relevance Score: 0.600):\nAudio File: SandalWoodNewsStories_176.mp3\nTime Range: 100.00s - 140.00s\nEnglish Translation: ([ 'Our farmers today, what has happened to them is that they have been relying on just one crop or one side business, and farmers are incurring huge losses, so we'], [' 'Our farmers today, what has happened to them is that they have been relying on just one crop or one side business, and farmers are incurring huge losses, so we']) (One of the objectives of this concept is to carry out comprehensive agriculture without borewells. Here, comprehensive agriculture means that the specialty of our Green Wood Farm is that], [One of the objectives of this concept is to carry out comprehensive agriculture without borewells. Here, comprehensive agriculture means that the specialty of our Green Wood Farm is that]) ([‘There is no such agriculture Anna. We have taken into consideration every agricultural concept in our farm sir. It means sheep, hen, fish, indigenous cow, earthworm, forest’], [‘There is no such agriculture Anna. We have taken into consideration every agricultural concept in our farm sir. It means sheep, hen, fish, indigenous cow, earthworm, forest’])\nOriginal Kannada: ([' ನಮ್ಮ ರೈತರು ಇವತ್ತ ಏನಾಗ್ತಾಯಿದ್ದಾರೆ ಅಂತಂದರೆ ಯಾವುದೋ ಒಂದು ಬೆಳೆಯನ್ನು ಒಂದು ಉಪಕಸಬನ್ನು ಒಂದನ್ನು ನಂಬ್ಕೊಂಡು ಹೋಗ್ತಾಯ್ದಿದ್ದಾರೆ ರೈತರು ತುಂಬ ಲಾಸ್ ಆಗ್ತಾಯಿದ್ದಾರೆ ಅದಕ್ಕಾಗಿ ನಾವು ಈ ಒಂದು ಮೂರುವರೆ ಎಕರೆೆಯಲ್ಲಿ'], [' ನಮ್ಮ ರೈತರು ಇವತ್ತ ಏನಾಗ್ತಾಯಿದ್ದಾರೆ ಅಂತಂದರೆ ಯಾವುದೋ ಒಂದು ಬೆಳೆಯನ್ನು ಒಂದು ಉಪಕಸಬನ್ನು ಒಂದನ್ನು ನಂಬ್ಕೊಂಡು ಹೋಗ್ತಾಯ್ದಿದ್ದಾರೆ ರೈತರು ತುಂಬ ಲಾಸ್ ಆಗ್ತಾಯಿದ್ದಾರೆ ಅದಕ್ಕಾಗಿ ನಾವು ಈ ಒಂದು ಮೂರುವರೆ ಎಕರೆೆಯಲ್ಲಿ']) ([' ಬೋರ್ ವಲ್ ಇಲ್ಲದೇನೆೇ ಒಂದು ಸಮಗ್ರ ಕೃಷಿಯನ್ನ ಮಾಡಿರ್ತಕ್ಕಥದ್ದು ಈ ಒಂದು ಕಾನ್ಸೆಪ್್ಟತ ನ ಒಂದು ಉದ್ದೇಶ ಆಗಿದೆ ಇಲ್ಲಿ ಸಮಗ್ರ ಕೃಷಿ ಅಂತಂದ್ರೆ ನಮ್ಮ ಈ ಒಂದು ಗ್ರೀನ್ ವಡ್ ಫಾರ್ಮ್ ನ ವಿಶೇಷತೆ ಏನಾಗಿದೆ ಅಂದ್ರೆ'], [' ಬೋರ್ ವಲ್ ಇಲ್ಲದೇನೆೇ ಒಂದು ಸಮಗ್ರ ಕೃಷಿಯನ್ನ ಮಾಡಿರ್ತಕ್ಕಥದ್ದು ಈ ಒಂದು ಕಾನ್ಸೆಪ್್ಟತ ನ ಒಂದು ಉದ್ದೇಶ ಆಗಿದೆ ಇಲ್ಲಿ ಸಮಗ್ರ ಕೃಷಿ ಅಂತಂದ್ರೆ ನಮ್ಮ ಈ ಒಂದು ಗ್ರೀನ್ ವಡ್ ಫಾರ್ಮ್ ನ ವಿಶೇಷತೆ ಏನಾಗಿದೆ ಅಂದ್ರೆ']) ([' ಇಂತ ಒಂದು ಆಗ್ರಿಕಲ್ಚರ ಇಲ್ಲ ಅನ್ನಂಗಿಲ್ಲ ನಮ್ ಫಾರ್ಮಲ ಪ್ರತಿಯೊಂದು ಆಗ್ರಿಕಲ್ಚರ ಕಾನ್ಸೆಪ್ಟತ ಉ ಇಟ್ಕೊಂಡಿದ್ವಿ ಸಿರ್ ಇದ್ರಲ್ಲಿ ಏನಂತಂದ್ರೆ ಕುರಿ ಕೋಳಿ ಮೀನು ದೇಶ್ಯ ಹಾಕಳು ಎರೆಹುಳು ಅರಣ್ಯ ಪ'], [' ಇಂತ ಒಂದು ಆಗ್ರಿಕಲ್ಚರ ಇಲ್ಲ ಅನ್ನಂಗಿಲ್ಲ ನಮ್ ಫಾರ್ಮಲ ಪ್ರತಿಯೊಂದು ಆಗ್ರಿಕಲ್ಚರ ಕಾನ್ಸೆಪ್ಟತ ಉ ಇಟ್ಕೊಂಡಿದ್ವಿ ಸಿರ್ ಇದ್ರಲ್ಲಿ ಏನಂತಂದ್ರೆ ಕುರಿ ಕೋಳಿ ಮೀನು ದೇಶ್ಯ ಹಾಕಳು ಎರೆಹುಳು ಅರಣ್ಯ ಪ'])\nExtracted Audio: /kaggle/working/extracted_segments2/segment_SandalWoodNewsStories_176.mp3_100.00_140.00.mp3\n----------------------------------------\n\nPassage 3 (Relevance Score: 0.500):\nAudio File: SandalWoodNewsStories_175.mp3\nTime Range: 170.00s - 210.00s\nEnglish Translation: [' Commercial name Trade name Today I want to say on this one occasion especially to our youth'], [' Commercial name Trade name Today I want to say on this one occasion especially to our youth']) ['Farmers and young people who have lands and are interested in agriculture, the land amendment act of 2001 and 2002'], ['Farmers and young people who have lands and are interested in agriculture, the land amendment act of 2001 and 2002']) [‘I must say that this is a great opportunity for a private person to grow sandalwood because in 1792, Tipu Sultan had done one'], [‘I must say that this is a great opportunity for a private person to grow sandalwood because in 1792, Tipu Sultan had done one’]\nOriginal Kannada: ([' ಕಮರ್ಷಿಯಲ್ ನೇಮ್ ವಾಣಿಜ್ಯ ಹೆಸರು ಇವತ್ತು ನಾನು ಈ ಒಂದು ಸಂದರ್ಭದಲ್ಲಿ ಹೇಳಬೇಕೆಂದ್ರ ವಿಶೇಷವಾಗಿ ನಮ್ಮ ಯುವ ರ'], [' ಕಮರ್ಷಿಯಲ್ ನೇಮ್ ವಾಣಿಜ್ಯ ಹೆಸರು ಇವತ್ತು ನಾನು ಈ ಒಂದು ಸಂದರ್ಭದಲ್ಲಿ ಹೇಳಬೇಕೆಂದ್ರ ವಿಶೇಷವಾಗಿ ನಮ್ಮ ಯುವ ರ']) ([' ರೈತರು ಯುವಕರು ಏನು ಭೂಮಿ ಇಟ್ಕೊಂಡಿದ್ದಾರೆ ಕೃಷಿ ಬಗ್ಗೆ ಆಸಕ್ತಿ ಇದೆ ಇವತ್ತೇನು ಎರಡು ಸಾವಿರದ ಒಂದು ಎರಡರಲ್ಲಿ ೇನು ಲಾ ಅಮೆಂಡ್ಮೆಂಟ್ ಆಗಿದೆ'], [' ರೈತರು ಯುವಕರು ಏನು ಭೂಮಿ ಇಟ್ಕೊಂಡಿದ್ದಾರೆ ಕೃಷಿ ಬಗ್ಗೆ ಆಸಕ್ತಿ ಇದೆ ಇವತ್ತೇನು ಎರಡು ಸಾವಿರದ ಒಂದು ಎರಡರಲ್ಲಿ ೇನು ಲಾ ಅಮೆಂಡ್ಮೆಂಟ್ ಆಗಿದೆ']) ([' ಪ್ರೈವೇಟ್ ಪರ್ಸನ್ ಕ್ಯಾನ್ ಗ್ರೋ ಸ್ಯಾಂಡಲ್ ಅಂತ ಇದೊಂದು ದೊಡ್ಡ ಅವಕಾಶ ಅಂತ ನಾನು ಹೇಳ್ಬೋದು ಈ ಸಂದರ್ಭದಲ್ಲಿ ಯಾಕಂತಂದರೆ ಹದಿನೇಳುನೂರ ಎಂಬತ್ತೆರಡರಲ್ಲಿ ಟಿಪ್ಪು ಸುಲ್ತಾನ್ ಮಾಡಿದ್ದ ಒಂದು'], [' ಪ್ರೈವೇಟ್ ಪರ್ಸನ್ ಕ್ಯಾನ್ ಗ್ರೋ ಸ್ಯಾಂಡಲ್ ಅಂತ ಇದೊಂದು ದೊಡ್ಡ ಅವಕಾಶ ಅಂತ ನಾನು ಹೇಳ್ಬೋದು ಈ ಸಂದರ್ಭದಲ್ಲಿ ಯಾಕಂತಂದರೆ ಹದಿನೇಳುನೂರ ಎಂಬತ್ತೆರಡರಲ್ಲಿ ಟಿಪ್ಪು ಸುಲ್ತಾನ್ ಮಾಡಿದ್ದ ಒಂದು'])\nExtracted Audio: /kaggle/working/extracted_segments2/segment_SandalWoodNewsStories_175.mp3_170.00_210.00.mp3\n----------------------------------------\n\nPassage 4 (Relevance Score: 0.500):\nAudio File: SandalWoodNewsStories_174.mp3\nTime Range: 580.00s - 620.00s\nEnglish Translation: [A farmer is not one who has a forehead indicating he would be a rider, sir, he must toil in the sun, get drenched in the rain and walk in the cold, only then will there be one or two bags of grain in his house], [A farmer is not one who has a forehead indicating he would be a rider, sir, he must toil in the sun, get drenched in the rain and walk in the cold, only then will there be one or two bags of grain in his house] ([' If he gets the rate, he will give two hundred rupees in his hand, if he doesn't get the rate then he will stand in front of the fertilizer shop and talk with bloodshot eyes, because he has made debts'], [' If he gets the rate, he will give two hundred rupees in his hand, if he doesn't get the rate then he will stand in front of the fertilizer shop and talk with bloodshot eyes, because he has made debts']) ([' Do, sir, this year keep the principal and next year I will pay the interest. He requested with folded hands, standing in front of you today. He says that if I speak, I will not see the day'], [' Do, sir, this year keep the principal and next year I will pay the interest. He requested with folded hands, standing in front of you today. He says that if I speak, I will not see the day'])\nOriginal Kannada: ([' ಸವಾರ ತಗೊಳ್ಳುವಂತ ಹಣೆ ಬರ ರೈತಂದ ಇರುವುದಿಲ್ಲ ಸಿರ ಅವನ ಬಿಸಲಲ್ಲಿ ಸೊಡಬೇಕಾಗ್ತದ ಮಳಿಯೊಳಗ ನೆನಿಬೇಕಾಗ್ತದ ಥಂಡಿಯೊಳಗ ನಡಗಬೇಕಾಗ್ತದ ಅವಾಗಷ್ಟ ಅವನ ಮನಿಯೊಳಗ ಒಂದ ಎರಡು ಚೀಲಾ ಕಾಳಿ ಇರ್ತಾವ'], [' ಸವಾರ ತಗೊಳ್ಳುವಂತ ಹಣೆ ಬರ ರೈತಂದ ಇರುವುದಿಲ್ಲ ಸಿರ ಅವನ ಬಿಸಲಲ್ಲಿ ಸೊಡಬೇಕಾಗ್ತದ ಮಳಿಯೊಳಗ ನೆನಿಬೇಕಾಗ್ತದ ಥಂಡಿಯೊಳಗ ನಡಗಬೇಕಾಗ್ತದ ಅವಾಗಷ್ಟ ಅವನ ಮನಿಯೊಳಗ ಒಂದ ಎರಡು ಚೀಲಾ ಕಾಳಿ ಇರ್ತಾವ']) ([' ರೇಟೆ ಸಿಕ್ಕ್ರೆ ಎಂತಿಿಕೈೊಳಗ್ ಎರಡ್ ಸಾವ್ರ ರೂಪಾಯ ಕೊಡ್ತಾನ ರೇಟೆ ಸಿಗ್ಲಿಲ್ಲ ಅಂದ್ರೆ ಗೊಬ್ಬರದ ಅಂಗಡಿ ಅವ್ನ್ ಮುಂದ್ ಹೋಗಿ ಕಣ್ಣಳಗ್ ಕಣ್ಣಿಟ್ ಮಾತಾಡ್ಲಿಕ್ಕ ಆಗಲ್ಲ ಸಿರ ಯಾಕಂದ್ರೆ ಸಾಲ ಮಾಡಿರ್ತಾನಲಿ ಕೆಳಗ್'], [' ರೇಟೆ ಸಿಕ್ಕ್ರೆ ಎಂತಿಿಕೈೊಳಗ್ ಎರಡ್ ಸಾವ್ರ ರೂಪಾಯ ಕೊಡ್ತಾನ ರೇಟೆ ಸಿಗ್ಲಿಲ್ಲ ಅಂದ್ರೆ ಗೊಬ್ಬರದ ಅಂಗಡಿ ಅವ್ನ್ ಮುಂದ್ ಹೋಗಿ ಕಣ್ಣಳಗ್ ಕಣ್ಣಿಟ್ ಮಾತಾಡ್ಲಿಕ್ಕ ಆಗಲ್ಲ ಸಿರ ಯಾಕಂದ್ರೆ ಸಾಲ ಮಾಡಿರ್ತಾನಲಿ ಕೆಳಗ್']) ([' ಮಾಡಿ ಯಪ್ಪಾ ಈ ವರ್ಷ ಅಸಲ ಇಟ್ಕೊಂಡ ಮುಂದಿನ ವರ್ಷ ಬಡ್ಡಿ ಕೊಡ್ತೀನಿ ಅಂತ ರೇಕೆಸ್ಟ್ ಮಾಡಿ ಕೈ ಮುಗಿದು ಬಂದಿರ್ತಾನೆ ಇವತ್ ನಿಮ್ಮ ಮುಂದ ನಿಿಂತ ನ ಮಾತಾಡ್ಲಿಕ್ಕತ್ತನ ಅಂದ್ರೆ ನಾ ದಿನಾ ನೋಡಿಲ್ಲ ಅಂತ ತಿಳ್ಕೊಂಡ'], [' ಮಾಡಿ ಯಪ್ಪಾ ಈ ವರ್ಷ ಅಸಲ ಇಟ್ಕೊಂಡ ಮುಂದಿನ ವರ್ಷ ಬಡ್ಡಿ ಕೊಡ್ತೀನಿ ಅಂತ ರೇಕೆಸ್ಟ್ ಮಾಡಿ ಕೈ ಮುಗಿದು ಬಂದಿರ್ತಾನೆ ಇವತ್ ನಿಮ್ಮ ಮುಂದ ನಿಿಂತ ನ ಮಾತಾಡ್ಲಿಕ್ಕತ್ತನ ಅಂದ್ರೆ ನಾ ದಿನಾ ನೋಡಿಲ್ಲ ಅಂತ ತಿಳ್ಕೊಂಡ'])\nExtracted Audio: /kaggle/working/extracted_segments2/segment_SandalWoodNewsStories_174.mp3_580.00_620.00.mp3\n----------------------------------------\n\nPassage 5 (Relevance Score: 0.491):\nAudio File: SandalWoodNewsStories_156.mp3\nTime Range: 290.00s - 330.00s\nEnglish Translation: ([Farmers are tilling the soil and doing all the ploughing and sowing in the agricultural land.], [Farmers are tilling the soil and doing all the ploughing and sowing in the agricultural land.]) (In the beginning, we put one manure of cow dung per each plant in the yard of Ratan Farm in the village of Doddhapalya), (Fertilizer in the beginning, manure of cow dung of Ratan Farm, yard of Doddhapalya, we put one manure per each plant) ([' It doesn't grow as good as it should. It grows poorly and the host plant with which it lives is important'], [' It doesn't grow as good as it should. It grows poorly and the host plant with which it lives is important'])\nOriginal Kannada: ([' ಫಾರ್ಮರ್ಸ್ ಆಗ್ರಿಕಲ್ಚರ ಲಂಡ್ ಅಲ್ಲಿ ಫೂಲ ಉಳುಮೆ ಮಾಡ್ಕೊಂಡು ಪ್ಲೋಇಂಗ್ ಎಲ್ಲ ಮಾಡಿ ನೆಟ್ಬೋದು ಆ'], [' ಫಾರ್ಮರ್ಸ್ ಆಗ್ರಿಕಲ್ಚರ ಲಂಡ್ ಅಲ್ಲಿ ಫೂಲ ಉಳುಮೆ ಮಾಡ್ಕೊಂಡು ಪ್ಲೋಇಂಗ್ ಎಲ್ಲ ಮಾಡಿ ನೆಟ್ಬೋದು ಆ']) ([' ಇನೀತಿಯಲ್ಲಿ ಗೊಬ್ಬರ ದನದ ವೆಲ್ ರಾಟನ್ ಫಾರ್ಮ ಯಾರ್ಡ್ ಮನ ದದೊ ಹ ಪ್ರತಿಯೊಂದು ಗಿಡಕ್ಕೆ ನಾವ ಒಂದು ಎರ ಬಿಡ್ತೀ'], [' ಇನೀತಿಯಲ್ಲಿ ಗೊಬ್ಬರ ದನದ ವೆಲ್ ರಾಟನ್ ಫಾರ್ಮ ಯಾರ್ಡ್ ಮನ ದದೊ ಹ ಪ್ರತಿಯೊಂದು ಗಿಡಕ್ಕೆ ನಾವ ಒಂದು ಎರ ಬಿಡ್ತೀ']) ([' ರಷ್ಟು ಹ ಹ ಉತ್ಕೃಷ್ಟವಾಗಿ ಬೆಳುತ್ತೆ ಅಂತೇಳಿತ್ೃಷ್ಟವಾಗಿ ಬೆಳತದೆ ಅದರ ಜೊತೆ ಹೋಸ್ಟ್ ಪ್ಲಾಂಟ್ ಹ ಹ ಹ ಅದು ಬಾಳ ಮುಖ್ಯ ಹ'], [' ರಷ್ಟು ಹ ಹ ಉತ್ಕೃಷ್ಟವಾಗಿ ಬೆಳುತ್ತೆ ಅಂತೇಳಿತ್ೃಷ್ಟವಾಗಿ ಬೆಳತದೆ ಅದರ ಜೊತೆ ಹೋಸ್ಟ್ ಪ್ಲಾಂಟ್ ಹ ಹ ಹ ಅದು ಬಾಳ ಮುಖ್ಯ ಹ'])\nExtracted Audio: /kaggle/working/extracted_segments2/segment_SandalWoodNewsStories_156.mp3_290.00_330.00.mp3\n----------------------------------------\n\nEntering interactive mode...\n",
          "output_type": "stream"
        },
        {
          "output_type": "stream",
          "name": "stdin",
          "text": "\nEnter your question (or 'quit' to exit):  quit\n"
        }
      ]
    }
  ]
}